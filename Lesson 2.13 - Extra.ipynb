{
 "metadata": {
  "name": "",
  "signature": "sha256:38fbfab131a90931ae458bf28ef159e8f8d2c04e0de6e85bd161794b26c21cd2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "# Let's assume that you combined the code from the previous 2 exercises\n",
      "# with code from the lesson on how to build requests, and downloaded all the data locally.\n",
      "# The files are in a directory \"data\", named after the carrier and airport:\n",
      "# \"{}-{}.html\".format(carrier, airport), for example \"FL-ATL.html\".\n",
      "# The table with flight info has a table class=\"dataTDRight\".\n",
      "# There are couple of helper functions to deal with the data files.\n",
      "# Please do not change them for grading purposes.\n",
      "# All your changes should be in the 'process_file' function\n",
      "# This is example of the datastructure you should return\n",
      "# Each item in the list should be a dictionary containing all the relevant data\n",
      "# Note - year, month, and the flight data should be integers\n",
      "# You should skip the rows that contain the TOTAL data for a year\n",
      "# data = [{\"courier\": \"FL\",\n",
      "#         \"airport\": \"ATL\",\n",
      "#         \"year\": 2012,\n",
      "#         \"month\": 12,\n",
      "#         \"flights\": {\"domestic\": 100,\n",
      "#                     \"international\": 100}\n",
      "#         },\n",
      "#         {\"courier\": \"...\"}\n",
      "# ]\n",
      "from bs4 import BeautifulSoup\n",
      "from zipfile import ZipFile\n",
      "import os\n",
      "import requests\n",
      "\n",
      "datadir = \"data\"\n",
      "\n",
      "s = requests.Session()\n",
      "\n",
      "r = s.get(\"http://www.transtats.bts.gov/Data_Elements.aspx?Data=2\")\n",
      "soup = BeautifulSoup(r.text)\n",
      "\n",
      "\n",
      "def open_zip(datadir):\n",
      "    with ZipFile('{0}.zip'.format(datadir), 'r') as myzip:\n",
      "        myzip.extractall()\n",
      "\n",
      "\n",
      "def process_all(datadir):\n",
      "    files = os.listdir(datadir)\n",
      "    return files\n",
      "\n",
      "def extract_carriers(soup):\n",
      "    data = []\n",
      "    carrier_list = soup.find(id = \"CarrierList\")\n",
      "    for option in carrier_list.find_all('option'):\n",
      "        if option['value'][:3] != \"All\":\n",
      "            data.append(option['value'])\n",
      "    return data\n",
      "\n",
      "def extract_airports(soup):\n",
      "    data = []\n",
      "    airport_list = soup.find(id=\"AirportList\")\n",
      "    for option in airport_list.find_all(\"option\"):\n",
      "        if option[\"value\"][:3] != \"All\":\n",
      "            data.append(option[\"value\"])\n",
      "    return data\n",
      "\n",
      "def extract_data(soup):\n",
      "    data = {\"eventvalidation\": \"\",\n",
      "            \"viewstate\": \"\"}\n",
      "    \n",
      "    ev = soup.find(id=\"__EVENTVALIDATION\")\n",
      "    data[\"eventvalidation\"] = ev[\"value\"]\n",
      "\n",
      "    vs = soup.find(id=\"__VIEWSTATE\")\n",
      "    data[\"viewstate\"]= vs[\"value\"]\n",
      "    \n",
      "    data[\"airport\"] = extract_airports(soup)\n",
      "    data[\"carrier\"] = extract_carriers(soup)\n",
      "    \n",
      "    return data\n",
      "\n",
      "\n",
      "\n",
      "def make_request(data=extract_data(soup)):\n",
      "    eventvalidation = data[\"eventvalidation\"]\n",
      "    viewstate = data[\"viewstate\"]\n",
      "    airport = data[\"airport\"][0]\n",
      "    carrier = data[\"carrier\"][0]\n",
      "    \n",
      "    \n",
      "    r = s.post(\"http://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
      "                    data={'AirportList': airport,\n",
      "                          'CarrierList': carrier,\n",
      "                          'Submit': 'Submit',\n",
      "                          \"__EVENTTARGET\": \"\",\n",
      "                          \"__EVENTARGUMENT\": \"\",\n",
      "                          \"__EVENTVALIDATION\": eventvalidation,\n",
      "                          \"__VIEWSTATE\": viewstate\n",
      "                    })\n",
      "\n",
      "    return r.text\n",
      "\n",
      "\n",
      "def process_file(f):\n",
      "    # This is example of the datastructure you should return\n",
      "    # Each item in the list should be a dictionary containing all the relevant data\n",
      "    # Note - year, month, and the flight data should be integers\n",
      "    # You should skip the rows that contain the TOTAL data for a year\n",
      "    # data = [{\"courier\": \"FL\",\n",
      "    #         \"airport\": \"ATL\",\n",
      "    #         \"year\": 2012,\n",
      "    #         \"month\": 12,\n",
      "    #         \"flights\": {\"domestic\": 100,\n",
      "    #                     \"international\": 100}\n",
      "    #         },\n",
      "    #         {\"courier\": \"...\"}\n",
      "    # ]\n",
      "    data = []\n",
      "    info = {}\n",
      "    info[\"courier\"], info[\"airport\"] = f[:6].split(\"-\")\n",
      "    \n",
      "    with open(\"{}/{}\".format(datadir, f), \"r\") as html:\n",
      "\n",
      "        #soup = BeautifulSoup(html)\n",
      "        validation_list = extract_data(soup)\n",
      "        carrier_list = extract_carriers(soup)\n",
      "        airport_list = extract_airports(soup)\n",
      "        #print validation_list, carrier_list, airport_list\n",
      "    \n",
      "    return data\n",
      "\n",
      "\n",
      "def test():\n",
      "    print \"Running a simple test...\"\n",
      "    #open_zip(datadir)\n",
      "    files = process_all(datadir)\n",
      "    data = []\n",
      "    for f in files:\n",
      "        data += process_file(f)\n",
      "    assert len(data) == 399\n",
      "    for entry in data[:3]:\n",
      "        assert type(entry[\"year\"]) == int\n",
      "        assert type(entry[\"flights\"][\"domestic\"]) == int\n",
      "        assert len(entry[\"airport\"]) == 3\n",
      "        assert len(entry[\"courier\"]) == 2\n",
      "    assert data[-1][\"airport\"] == \"ATL\"\n",
      "    assert data[-1][\"flights\"] == {'international': 108289, 'domestic': 701425}\n",
      "    \n",
      "    print \"... success!\"\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    #test()\n",
      "    f = open(\"test.html\", \"w\")\n",
      "    f.write(make_request())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a network tab on the \"Developer Tools\" of chrome that lets you see what element the post request forwards.\n",
      "\n",
      "Aso for use the requests.Session() to retain cookies information and stuff.\n",
      "\n",
      "\n",
      "<img src=\"network.png\">"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}